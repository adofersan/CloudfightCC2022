{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloudfight Coding Contest AI 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix and plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, LabelBinarizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Models\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1      2      3       4       5       6      7\n",
      "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.150\n",
      "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.070\n",
      "2  F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.210\n",
      "3  M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.155\n",
      "4  I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.055\n",
      "0    15\n",
      "1     7\n",
      "2     9\n",
      "3    10\n",
      "4     7\n",
      "Name: 8, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"abalone.data\"\n",
    "df = pd.read_csv(DATA_PATH, header=None)\n",
    "X = df.iloc[:, 0:-1]  # Get first k-1 cols\n",
    "print(X.head())\n",
    "y = df.iloc[:, -1]  # Get last col\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum(axis=0))\n",
    "\n",
    "# # Numeric vars\n",
    "num_idx_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "num_imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "num_imp.fit(X.select_dtypes(include=np.number))\n",
    "X.iloc[:, num_idx_cols] = num_imp.transform(X.select_dtypes(include=np.number))\n",
    "\n",
    "# Cat vars\n",
    "cat_idx_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categoricalImputer = SimpleImputer(\n",
    "    missing_values=None, strategy='most_frequent')\n",
    "categoricalImputer.fit(X.select_dtypes(include=[\"object\"]))\n",
    "X.iloc[:, cat_idx_cols] = categoricalImputer.transform(\n",
    "    X.select_dtypes(include=[\"object\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical attributes to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1      2      3       4       5       6       7    0    1    2\n",
      "0     0.455  0.365  0.095  0.5140  0.2245  0.1010  0.1500  0.0  0.0  1.0\n",
      "1     0.350  0.265  0.090  0.2255  0.0995  0.0485  0.0700  0.0  0.0  1.0\n",
      "2     0.530  0.420  0.135  0.6770  0.2565  0.1415  0.2100  1.0  0.0  0.0\n",
      "3     0.440  0.365  0.125  0.5160  0.2155  0.1140  0.1550  0.0  0.0  1.0\n",
      "4     0.330  0.255  0.080  0.2050  0.0895  0.0395  0.0550  0.0  1.0  0.0\n",
      "...     ...    ...    ...     ...     ...     ...     ...  ...  ...  ...\n",
      "4172  0.565  0.450  0.165  0.8870  0.3700  0.2390  0.2490  1.0  0.0  0.0\n",
      "4173  0.590  0.440  0.135  0.9660  0.4390  0.2145  0.2605  0.0  0.0  1.0\n",
      "4174  0.600  0.475  0.205  1.1760  0.5255  0.2875  0.3080  0.0  0.0  1.0\n",
      "4175  0.625  0.485  0.150  1.0945  0.5310  0.2610  0.2960  1.0  0.0  0.0\n",
      "4176  0.710  0.555  0.195  1.9485  0.9455  0.3765  0.4950  0.0  0.0  1.0\n",
      "\n",
      "[4177 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "CAT_COLS = [0]\n",
    "cat_cols_encoded = pd.DataFrame(enc.fit_transform(X[CAT_COLS]).toarray())\n",
    "X = X.drop(columns=CAT_COLS)\n",
    "X = pd.concat([X, cat_cols_encoded], axis=1)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode multiple class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = LabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_COLS = X.columns\n",
    "X = pd.DataFrame(RobustScaler().fit_transform(X[NORMALIZE_COLS]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1         2    3    4         5         6         7  \\\n",
      "0    -0.545455  0.0 -0.461538  1.0 -0.9 -0.401265 -0.352848 -0.438871   \n",
      "1    -1.181818  0.0 -1.230769  1.0 -1.0 -0.806746 -0.748418 -0.768025   \n",
      "2    -0.090909  0.0 -0.038462  0.0 -0.1 -0.172171 -0.251582 -0.184953   \n",
      "3    -0.636364  0.0 -0.461538  1.0 -0.3 -0.398454 -0.381329 -0.357367   \n",
      "4    -1.303030  1.0 -1.307692  0.0 -1.2 -0.835559 -0.780063 -0.824451   \n",
      "...        ...  ...       ...  ...  ...       ...       ...       ...   \n",
      "4172  0.121212  0.0  0.192308  0.0  0.5  0.122980  0.107595  0.426332   \n",
      "4173  0.272727  0.0  0.115385  1.0 -0.1  0.234013  0.325949  0.272727   \n",
      "4174  0.333333  0.0  0.384615  1.0  1.3  0.529164  0.599684  0.730408   \n",
      "4175  0.484848  0.0  0.461538  0.0  0.2  0.414617  0.617089  0.564263   \n",
      "4176  1.000000  0.0  1.000000  1.0  1.1  1.614898  1.928797  1.288401   \n",
      "\n",
      "             8    9        10   11        12   13   14        15   16  \\\n",
      "0    -0.422111  0.0 -0.545455  0.0 -0.461538  1.0  0.0 -0.461538  0.0   \n",
      "1    -0.824121  0.0 -1.181818  0.0 -1.230769  1.0  0.0 -1.230769  0.0   \n",
      "2    -0.120603  1.0 -0.090909  0.0 -0.038462  0.0  0.0 -0.038462  0.0   \n",
      "3    -0.396985  0.0 -0.636364  0.0 -0.461538  1.0  0.0 -0.461538  0.0   \n",
      "4    -0.899497  0.0 -1.303030  1.0 -1.307692  0.0  1.0 -1.307692  1.0   \n",
      "...        ...  ...       ...  ...       ...  ...  ...       ...  ...   \n",
      "4172  0.075377  1.0  0.121212  0.0  0.192308  0.0  0.0  0.192308  0.0   \n",
      "4173  0.133166  0.0  0.272727  0.0  0.115385  1.0  0.0  0.115385  0.0   \n",
      "4174  0.371859  0.0  0.333333  0.0  0.384615  1.0  0.0  0.384615  0.0   \n",
      "4175  0.311558  1.0  0.484848  0.0  0.461538  0.0  0.0  0.461538  0.0   \n",
      "4176  1.311558  0.0  1.000000  0.0  1.000000  1.0  0.0  1.000000  0.0   \n",
      "\n",
      "            17   18        19  \n",
      "0     0.213018  0.0 -0.098316  \n",
      "1     1.514793  0.0 -1.864360  \n",
      "2     0.001479  0.0 -0.000057  \n",
      "3     0.213018  0.0 -0.098316  \n",
      "4     1.710059  1.0 -2.236231  \n",
      "...        ...  ...       ...  \n",
      "4172  0.036982  0.0  0.007112  \n",
      "4173  0.013314  0.0  0.001536  \n",
      "4174  0.147929  0.0  0.056896  \n",
      "4175  0.213018  0.0  0.098316  \n",
      "4176  1.000000  0.0  1.000000  \n",
      "\n",
      "[4177 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "VARIABLES = [0,1,2,3,4]\n",
    "MOMENTS = [2, 3]\n",
    "X_moments = [X[VARIABLES].pow(m) for m in MOMENTS]\n",
    "\n",
    "X = pd.concat([X] + X_moments, axis=1)\n",
    "X.columns = [str(i) for i in range(len(X.columns))]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 20\n",
    "CV = 4\n",
    "RANDOM_STATE = 2022\n",
    "N_JOBS = 1\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-1.5336161335186163\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\"n_estimators\": np.arange(10, 210, step=10),\n",
    "              \"eta\": np.arange(0.01, 0.3, step=0.01),\n",
    "              \"subsample\": np.arange(0.5, 1, step=0.05),\n",
    "              \"colsample_bytree\": np.arange(0.5, 1, step=0.05),\n",
    "              \"max_depth\": np.arange(3, 10, step=1),\n",
    "              \"min_child_weight\": np.arange(1, 5, step=0.05),\n",
    "              \"random_state\": [RANDOM_STATE]}\n",
    "\n",
    "xgb_models = RandomizedSearchCV(estimator=XGBRegressor(),n_jobs=N_JOBS, param_distributions=xgb_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                               scoring='neg_mean_absolute_error', random_state=RANDOM_STATE)\n",
    "xgb_models.fit(X, y)\n",
    "best_models[xgb_models.best_estimator_] = xgb_models.best_score_\n",
    "print(xgb_models.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-1.553051557144041\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = {\"n_estimators\": np.arange(10, 210, step=10),\n",
    "              \"learning_rate\": np.arange(0.01, 0.3, step=0.01),\n",
    "              \"subsample\": np.arange(0.5, 1, step=0.05),\n",
    "              \"colsample_bytree\": np.arange(0.5, 1, step=0.05),\n",
    "              \"max_depth\": np.arange(3, 10, step=1),\n",
    "              \"min_child_weight\": np.arange(1, 5, step=0.05),\n",
    "              \"random_state\": [RANDOM_STATE]}\n",
    "\n",
    "lgbm_models = RandomizedSearchCV(estimator=LGBMRegressor(),n_jobs=N_JOBS, param_distributions=lgbm_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                                 scoring='neg_mean_absolute_error', random_state=RANDOM_STATE)\n",
    "lgbm_models.fit(X, y)\n",
    "best_models[lgbm_models.best_estimator_] = lgbm_models.best_score_\n",
    "print(lgbm_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "-1.4855499157113923\n"
     ]
    }
   ],
   "source": [
    "svm_params = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"degree\": [1, 2, 3, 4],\n",
    "    \"epsilon\": np.arange(0.001, 1, step=0.001),\n",
    "    \"C\": np.arange(1, 100, step=1),\n",
    "    # \"random_state\": [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "svm_models = RandomizedSearchCV(estimator=SVR(), n_jobs=N_JOBS, param_distributions=svm_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                                scoring='neg_mean_absolute_error', random_state=RANDOM_STATE)\n",
    "svm_models.fit(X, y)\n",
    "best_models[svm_models.best_estimator_] = svm_models.best_score_\n",
    "print(svm_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "-1.4981509229564964\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_depth\": np.arange(10, 110, step=5),\n",
    "    \"max_features\": np.arange(0.5, 1, step=0.05),\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"n_estimators\": np.arange(10, 210, step=10),\n",
    "    \"random_state\": [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "rf_models = RandomizedSearchCV(estimator=RandomForestRegressor(), n_jobs=N_JOBS, param_distributions=rf_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                               scoring='neg_mean_absolute_error', random_state=RANDOM_STATE)\n",
    "rf_models.fit(X, y)\n",
    "best_models[rf_models.best_estimator_] = rf_models.best_score_\n",
    "print(rf_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(best_models, key=best_models.get)\n",
    "# X_predict = pd.read_csv()\n",
    "# best_model.predict(X_predict)\n",
    "# X_predict.to_csv(\"results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e957659887d768ade60a9d6facc275d27c264b5bb0dcb8a0edc1a78494747767"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
