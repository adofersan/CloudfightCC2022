{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloudfight Coding Contest AI 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install scikit-learn\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix and plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, LabelBinarizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"abalone.data\"\n",
    "df = pd.read_csv(DATA_PATH, header=None)\n",
    "X = df.iloc[:, 0:-1]  # Get first k-1 cols\n",
    "print(X.head())\n",
    "y = df.iloc[:, -1]  # Get last col\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.isnull().sum(axis=0))\n",
    "\n",
    "# # Numeric vars\n",
    "num_idx_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "num_imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "num_imp.fit(X.select_dtypes(include=np.number))\n",
    "X.iloc[:, num_idx_cols] = num_imp.transform(X.select_dtypes(include=np.number))\n",
    "\n",
    "# Cat vars\n",
    "cat_idx_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categoricalImputer = SimpleImputer(\n",
    "    missing_values=None, strategy='most_frequent')\n",
    "categoricalImputer.fit(X.select_dtypes(include=[\"object\"]))\n",
    "X.iloc[:, cat_idx_cols] = categoricalImputer.transform(\n",
    "    X.select_dtypes(include=[\"object\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical attributes to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "CAT_COLS = [0]\n",
    "cat_cols_encoded = pd.DataFrame(enc.fit_transform(X[CAT_COLS]).toarray())\n",
    "X = X.drop(columns=CAT_COLS)\n",
    "X = pd.concat([X, cat_cols_encoded], axis=1)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode multiple class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_COLS = X.columns\n",
    "X = pd.DataFrame(RobustScaler().fit_transform(X[NORMALIZE_COLS]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES = [0,1,2,3,4]\n",
    "MOMENTS = [2, 3]\n",
    "X_moments = [X[VARIABLES].pow(m) for m in MOMENTS]\n",
    "\n",
    "X = pd.concat([X] + X_moments, axis=1)\n",
    "X.columns = [str(i) for i in range(len(X.columns))]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 20\n",
    "CV = 4\n",
    "RANDOM_STATE = 2022\n",
    "N_JOBS = 1\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\"n_estimators\": np.arange(10, 210, step=10),\n",
    "              \"eta\": np.arange(0.01, 0.3, step=0.01),\n",
    "              \"subsample\": np.arange(0.5, 1, step=0.05),\n",
    "              \"colsample_bytree\": np.arange(0.5, 1, step=0.05),\n",
    "              \"max_depth\": np.arange(3, 10, step=1),\n",
    "              \"min_child_weight\": np.arange(1, 5, step=0.05),\n",
    "              \"random_state\": [RANDOM_STATE]}\n",
    "\n",
    "xgb_models = RandomizedSearchCV(estimator=XGBClassifier(), n_jobs=N_JOBS, param_distributions=xgb_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                                scoring='accuracy', random_state=RANDOM_STATE)\n",
    "xgb_models.fit(X, y)\n",
    "best_models[xgb_models.best_estimator_] = xgb_models.best_score_\n",
    "print(xgb_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\"n_estimators\": np.arange(10, 210, step=10),\n",
    "               \"learning_rate\": np.arange(0.01, 0.3, step=0.01),\n",
    "               \"subsample\": np.arange(0.5, 1, step=0.05),\n",
    "               \"colsample_bytree\": np.arange(0.5, 1, step=0.05),\n",
    "               \"max_depth\": np.arange(3, 10, step=1),\n",
    "               \"min_child_weight\": np.arange(1, 5, step=0.05),\n",
    "               \"random_state\": [RANDOM_STATE]}\n",
    "\n",
    "lgbm_models = RandomizedSearchCV(estimator=LGBMClassifier(), n_jobs=N_JOBS, param_distributions=lgbm_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                                 scoring='accuracy', random_state=RANDOM_STATE)\n",
    "lgbm_models.fit(X, y)\n",
    "best_models[lgbm_models.best_estimator_] = lgbm_models.best_score_\n",
    "print(lgbm_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"degree\": [1, 2, 3, 4],\n",
    "    \"epsilon\": np.arange(0.001, 1, step=0.001),\n",
    "    \"C\": np.arange(1, 100, step=1),\n",
    "    \"random_state\": [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "svm_models = RandomizedSearchCV(estimator=SVC(), n_jobs=N_JOBS, param_distributions=svm_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                                scoring='accuracy', random_state=RANDOM_STATE)\n",
    "svm_models.fit(X, y)\n",
    "best_models[svm_models.best_estimator_] = svm_models.best_score_\n",
    "print(svm_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_depth\": np.arange(10, 110, step=5),\n",
    "    \"max_features\": np.arange(0.5, 1, step=0.05),\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"n_estimators\": np.arange(10, 210, step=10),\n",
    "    \"random_state\": [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "rf_models = RandomizedSearchCV(estimator=RandomForestClassifier(), n_jobs=N_JOBS, param_distributions=rf_params, n_iter=N_ITER,  verbose=1, cv=CV,\n",
    "                               scoring='accuracy', random_state=RANDOM_STATE)\n",
    "rf_models.fit(X, y)\n",
    "best_models[rf_models.best_estimator_] = rf_models.best_score_\n",
    "print(rf_models.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(best_models, key=best_models.get)\n",
    "# X_predict = pd.read_csv()\n",
    "# best_model.predict(X_predict)\n",
    "# X_predict.to_csv(\"results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f38b9e01a9fe127fd7ffec778475588ec2d96979cda27cfc0ff6ec681b66c38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
